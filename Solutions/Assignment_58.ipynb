{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f0b8e0-35ad-4718-94a6-0032ea315659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1\n",
    "\n",
    "# In machine learning, kernel functions are used to transform the input data into a higher-dimensional space, allowing for the separation of data points that are not linearly separable in the original space. Polynomial kernel functions are a type of kernel function that calculates the similarity between data points using polynomial functions. The polynomial kernel function is defined as K(x, y) = (x * y + c)^d, where x and y are data points, c is an optional constant, and d is the degree of the polynomial.\n",
    "\n",
    "# The polynomial kernel function implicitly computes the dot product of data points in a higher-dimensional space without explicitly calculating the transformation. This enables algorithms like Support Vector Machines (SVMs) to work with nonlinear decision boundaries by using the kernel trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22cfe3f1-1194-482d-be9a-3eac345fcea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Answer 2\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the SVM classifier with a polynomial kernel\n",
    "svm_classifier = SVC(kernel='poly', degree=3)  # You can adjust the degree\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained classifier to predict the labels of the testing data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier using accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca292479-7bed-4eb1-bfa6-7aafab3cfecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3\n",
    "\n",
    "# In Support Vector Regression (SVR), the parameter epsilon (ε) defines a margin around the predicted regression line within which errors are tolerated. When you increase the value of epsilon, you are allowing a wider margin, which means that data points can fall farther from the predicted regression line while still being considered support vectors.\n",
    "\n",
    "# Increasing the value of epsilon generally leads to an increase in the number of support vectors. This is because larger epsilon values allow more data points to be within the margin and still contribute to the formulation of the SVR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b033ad9-1376-457d-9b42-55afaa6535ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4\n",
    "\n",
    "# Kernel Function: The choice of the kernel function affects how well SVR can model nonlinear relationships in the data. Different kernel functions (such as linear, polynomial, radial basis function, etc.) are suitable for different types of data and relationships.\n",
    "\n",
    "# C Parameter: The C parameter trades off between achieving a low training error and a low testing error. A smaller C allows a wider margin and allows some training errors, while a larger C aims for a smaller margin with fewer training errors.\n",
    "\n",
    "# Epsilon (ε) Parameter: Epsilon defines the margin of tolerance around the regression line. Larger epsilon values result in wider margins and more support vectors, while smaller epsilon values lead to narrower margins and fewer support vectors.\n",
    "\n",
    "# Gamma Parameter: The gamma parameter is specific to kernel functions that use it (like the radial basis function). It influences the shape of the decision boundary. Smaller gamma values produce a more generalized boundary, while larger gamma values can lead to overfitting.\n",
    "\n",
    "# The optimal values for these parameters depend on the nature of the data and the specific problem. It's crucial to tune them using techniques like GridSearchCV or RandomizedSearchCV to find the best combination for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c600f9e6-1c38-4b0a-bab8-8cd1a9b3189d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n",
      "Best Parameters: {'C': 10, 'degree': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tuned_svm_classifier.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 5\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the SVC classifier with a polynomial kernel\n",
    "svm_classifier = SVC(kernel='poly')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the trained classifier to predict the labels of the testing data\n",
    "y_pred = svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of the classifier using accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Tune the hyperparameters using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'degree': [2, 3, 4],\n",
    "}\n",
    "grid_search = GridSearchCV(SVC(kernel='poly'), param_grid, cv=3)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "tuned_svm_classifier = SVC(kernel='poly', **best_params)\n",
    "tuned_svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the trained classifier to a file\n",
    "joblib.dump(tuned_svm_classifier, 'tuned_svm_classifier.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19d346-97fd-40d7-8369-da87282273e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
