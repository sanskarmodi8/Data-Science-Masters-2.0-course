{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba15209-a0ec-4862-baff-11aec2d84052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1\n",
    "\n",
    "# Grid Search Cross-Validation (Grid Search CV) is used for hyperparameter tuning in machine learning models. It's the process of systematically searching through a specified hyperparameter space to find the combination of hyperparameters that yields the best performance for a given model.\n",
    "\n",
    "# Grid Search CV works by defining a grid of possible hyperparameter values for each hyperparameter you want to tune. It then exhaustively trains and evaluates the model for all possible combinations of hyperparameters using cross-validation. The performance metric (e.g., accuracy, F1-score) is used to determine the optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a994202-544b-42d4-ac45-2e669fbd1ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2\n",
    "\n",
    "# Grid Search CV: Searches through all possible combinations of hyperparameters in the specified grid.\n",
    "# Randomized Search CV: Randomly samples a specified number of combinations from the hyperparameter space.\n",
    "# Choose Grid Search CV when you have a small hyperparameter space and want to exhaustively search all possibilities. Choose Randomized Search CV when the hyperparameter space is large and searching all combinations is computationally expensive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "259584d0-87b9-4fb7-8500-98203594d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3\n",
    "\n",
    "# Data leakage occurs when information from the test set (unseen data) unintentionally influences the training process. This leads to overly optimistic performance estimates, as the model effectively learns from information it shouldn't have access to.\n",
    "\n",
    "# Example: Imagine you're building a credit default prediction model. If you use future information (e.g., future loan status) as a feature during training, the model would perform exceptionally well on the test set because it has indirectly learned the future outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b570ccc5-5b73-4c2e-b2fa-50b3fd06e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4\n",
    "\n",
    "# Use Proper Cross-Validation: Make sure to perform cross-validation correctly to simulate the real-world scenario where the model is trained on historical data and tested on future data.\n",
    "# Feature Engineering: Avoid using features that contain information not available at the time of prediction.\n",
    "# Time-Based Splits: If dealing with temporal data, use time-based splits to ensure no future information leaks into the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc574dda-3cd6-40a0-95cf-2f19b3b3517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5\n",
    "\n",
    "# A confusion matrix is a table that summarizes the performance of a classification model by showing the counts of true positive, true negative, false positive, and false negative predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad5775f-ba3d-46e7-995e-8edc9595404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6\n",
    "\n",
    "# Precision: The ratio of true positive predictions to the total number of positive predictions made by the model. It measures the accuracy of positive predictions.\n",
    "# Recall: The ratio of true positive predictions to the total number of actual positive instances in the dataset. It measures the model's ability to correctly identify positive instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7adea6cb-d5b3-4e1b-95d8-00dbf0ce2084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7\n",
    "\n",
    "# Focus on the diagonal elements (true positives and true negatives) to understand the model's correct predictions.\n",
    "# Analyze off-diagonal elements to identify false positives and false negatives and understand the types of errors the model is making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0429e9f0-5cc1-47b0-b272-de14fd46a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8\n",
    "\n",
    "# Accuracy: Overall proportion of correctly predicted instances.\n",
    "# Precision: Ratio of true positives to the total number of predicted positives.\n",
    "# Recall: Ratio of true positives to the total number of actual positives.\n",
    "# F1-score: Harmonic mean of precision and recall, balancing both metrics.\n",
    "# Specificity (True Negative Rate): Ratio of true negatives to the total number of actual negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "734aa9b5-725d-4fb7-8e84-10d0e8b3e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 9\n",
    "\n",
    "# Accuracy is the ratio of correct predictions to the total number of predictions. It's affected by the distribution of classes and can be misleading, especially in imbalanced datasets. A good model should have high accuracy but should also be evaluated using other metrics from the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed2c7b-b5c4-45ad-abeb-a9ac840ede51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 10\n",
    "\n",
    "# Analyzing the confusion matrix can reveal biases or limitations in a model:\n",
    "\n",
    "# If the model has high accuracy but low recall, it might be biased towards the majority class.\n",
    "# If there's a large number of false positives or false negatives, investigate the reasons for these errors.\n",
    "# Understanding the confusion matrix helps uncover potential areas for improvement and provides insights into model behavior.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
