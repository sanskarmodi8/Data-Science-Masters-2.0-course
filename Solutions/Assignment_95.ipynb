{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfadd065-9fec-44ca-a16c-c96e047236ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.15,>=2.14.0\n",
      "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.1)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt<1.15,>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Collecting tensorflow-estimator<2.15,>=2.14.0\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Collecting tensorboard<2.15,>=2.14\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.11)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting ml-dtypes==0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.23.3-py2.py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.28.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.5-py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.0-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.6/226.6 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, opt-einsum, ml-dtypes, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.0 keras-2.14.0 libclang-16.0.6 markdown-3.5 ml-dtypes-0.2.0 opt-einsum-3.3.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.14.1 tensorboard-data-server-0.7.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.3.0 werkzeug-3.0.0 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c476cb73-8f5c-40f2-81c3-f6b11fed0d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2186 - accuracy: 0.9331 - val_loss: 0.0713 - val_accuracy: 0.9782\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0707 - accuracy: 0.9786 - val_loss: 0.0574 - val_accuracy: 0.9826\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0503 - accuracy: 0.9844 - val_loss: 0.0642 - val_accuracy: 0.9802\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0389 - accuracy: 0.9873 - val_loss: 0.0472 - val_accuracy: 0.9862\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0322 - accuracy: 0.9895 - val_loss: 0.0469 - val_accuracy: 0.9859\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0471 - accuracy: 0.9847\n",
      "Test accuracy: 0.9847000241279602\n"
     ]
    }
   ],
   "source": [
    "# Understanding Pooling and Padding in CNN:\n",
    "\n",
    "# QUES 1) Purpose and Benefits of Pooling in CNN:\n",
    "\n",
    "# Pooling is a crucial operation in Convolutional Neural Networks (CNNs) that helps reduce the spatial dimensions of the feature maps while retaining important information.\n",
    "# Its primary purpose is to make the network translation invariant, meaning it can recognize patterns in different parts of an image.\n",
    "# Pooling helps reduce the computational cost and the number of parameters in the network while preventing overfitting.\n",
    "# Common pooling methods include max pooling and average pooling.\n",
    "\n",
    "# QUES 2) Difference between Max Pooling and Average Pooling:\n",
    "\n",
    "# Max pooling selects the maximum value from a group of neighboring pixels, which helps in preserving the most prominent features in the feature map.\n",
    "# Average pooling, on the other hand, calculates the average value of the pixels in the group. It is useful for smoothing and reducing noise in the feature maps.\n",
    "\n",
    "# QUES 3)  Padding in CNN and its Significance:\n",
    "\n",
    "# Padding is a technique used to control the spatial dimensions of the output feature maps after convolution or pooling operations.\n",
    "# Padding involves adding extra pixels (usually zeros) around the input image or feature map before applying convolution or pooling.\n",
    "# Padding is important for maintaining the spatial dimensions, especially when using small filter sizes and to ensure that features at the borders of the image are adequately processed.\n",
    "\n",
    "# QUES 4) Comparison of Zero-padding and Valid-padding:\n",
    "\n",
    "# Zero-padding adds zeros around the input image or feature map to maintain spatial dimensions. It is also known as \"same padding.\"\n",
    "# Valid-padding does not add any extra pixels, which results in the output feature map being smaller than the input.\n",
    "# Zero-padding is commonly used to ensure that the output size matches the input size when needed, while valid-padding reduces the spatial dimensions.\n",
    "\n",
    "\n",
    "# LeNet-5:\n",
    "\n",
    "# QUES 1) Overview of LeNet-5 Architecture:\n",
    "\n",
    "# LeNet-5 is a classic convolutional neural network designed by Yann Lecun for handwritten digit recognition.\n",
    "# It consists of several layers, including two convolutional layers, two pooling layers, and three fully connected layers.\n",
    "\n",
    "# QUES 2) Key Components and Their Purposes:\n",
    "\n",
    "# Convolutional Layers: These layers extract features from the input image.\n",
    "# Pooling Layers: They downsample the feature maps, reducing computational load.\n",
    "# Fully Connected Layers: These layers perform classification based on the extracted features.\n",
    "\n",
    "# QUES 3) Advantages and Limitations of LeNet-5:\n",
    "\n",
    "# Advantages:\n",
    "# LeNet-5 was groundbreaking for image classification tasks, demonstrating the effectiveness of convolutional neural networks.\n",
    "# It is lightweight and computationally efficient.\n",
    "# Limitations:\n",
    "# It may not perform as well on complex, large-scale datasets as more modern architectures.\n",
    "# The architecture may not be deep enough to capture intricate features in some tasks.\n",
    "\n",
    "# QUES 4)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a LeNet-5 model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(layers.Conv2D(6, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(16, (5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the feature maps\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(layers.Dense(120, activation='relu'))\n",
    "model.add(layers.Dense(84, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))  # 10 is the number of output classes (for MNIST)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load the MNIST dataset and train the model\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0  # Normalize\n",
    "\n",
    "# Split a portion of training data for validation\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5, validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7f487b2-0510-4095-a791-8a18c2ac6266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 21s 13ms/step - loss: 0.2293 - accuracy: 0.9281 - val_loss: 0.0948 - val_accuracy: 0.9707\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 19s 13ms/step - loss: 0.0768 - accuracy: 0.9762 - val_loss: 0.0860 - val_accuracy: 0.9734\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 19s 13ms/step - loss: 0.0541 - accuracy: 0.9833 - val_loss: 0.0599 - val_accuracy: 0.9824\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 19s 13ms/step - loss: 0.0412 - accuracy: 0.9868 - val_loss: 0.0559 - val_accuracy: 0.9836\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 19s 13ms/step - loss: 0.0330 - accuracy: 0.9893 - val_loss: 0.0662 - val_accuracy: 0.9808\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0660 - accuracy: 0.9816\n",
      "Test accuracy: 0.9815999865531921\n"
     ]
    }
   ],
   "source": [
    "# AlexNet:\n",
    "\n",
    "# QUES 1) Overview of AlexNet Architecture:\n",
    "\n",
    "# AlexNet is a deep convolutional neural network designed by Alex Krizhevsky for the ImageNet Large Scale Visual Recognition Challenge.\n",
    "# It marked a breakthrough in deep learning and led to a significant improvement in image classification accuracy.\n",
    "\n",
    "# QUES 2) Architectural Innovations in AlexNet:\n",
    "\n",
    "# AlexNet introduced several innovations, including the use of rectified linear units (ReLU), dropout, and data augmentation, contributing to its superior performance.\n",
    "# It also used a deeper architecture with multiple convolutional and fully connected layers.\n",
    "\n",
    "# QUES 3) Roles of Different Layers in AlexNet:\n",
    "\n",
    "# Convolutional Layers: These layers extract high-level features from images.\n",
    "# Pooling Layers: They downsample the feature maps.\n",
    "# Fully Connected Layers: These layers perform classification based on the extracted features.\n",
    "\n",
    "# QUES 4)\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Expand dimensions to (28, 28, 1)\n",
    "train_images = train_images[..., tf.newaxis].astype(\"float32\")\n",
    "test_images = test_images[..., tf.newaxis].astype(\"float32\")\n",
    "\n",
    "# Split a portion of training data for validation\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an AlexNet-like model for MNIST\n",
    "model = models.Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the feature maps\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))  # 10 is the number of output classes for MNIST\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with training and validation data\n",
    "model.fit(train_images, train_labels, epochs=5, validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680956bd-4a16-4b85-abf6-71c0953138eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
