{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45cb2a6-5451-407f-a97f-5b0ae1de2260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1\n",
    "\n",
    "# A decision tree classifier is a machine learning algorithm used for both classification and regression tasks. It works by recursively partitioning the feature space into subsets, aiming to create regions that are as pure as possible in terms of the target variable (for classification, this could be class labels). The algorithm builds a tree-like structure where each internal node represents a decision based on a particular feature, and each leaf node represents a class label or a regression value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd4e3276-a498-4779-9e98-58f6ffa4cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2\n",
    "\n",
    "# Selecting a Feature: The algorithm starts by selecting the feature that best separates the data into different classes. This is typically done using metrics like Gini impurity or entropy.\n",
    "\n",
    "# Splitting: Once a feature is chosen, the data is split at a certain threshold value for that feature. The split is chosen to maximize the separation of classes based on the chosen impurity metric.\n",
    "\n",
    "# Repeating the Process: The above steps are repeated recursively for each subset created by the split until a stopping condition is met. This could be a maximum depth limit, a minimum number of samples per leaf, or reaching a perfectly pure subset.\n",
    "\n",
    "# Assigning Labels: Once the tree is built, new data points are traversed down the tree by comparing their feature values to the decision thresholds at each internal node. The leaf node reached is then assigned the class label of the majority of training samples within that leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c2d8e53-294c-43cd-b873-0186881034cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3\n",
    "\n",
    "# Let's say you have a dataset with features (attributes) and corresponding binary class labels (0 or 1). A decision tree classifier would use the features to make decisions about how to split the data into subsets that are as pure as possible in terms of class labels. For instance, it might split based on a feature like age: if age < 30, go left, otherwise go right. This process continues, creating a tree structure until a stopping condition is met. Once the tree is built, when you provide a new data point's feature values, the tree traverses its structure to reach a leaf node, which then predicts the class label for that data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a02fe8-877a-484c-bc9d-f7f460830b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4\n",
    "\n",
    "# Geometrically, a decision tree divides the feature space into regions, where each region corresponds to a path from the root node to a leaf node. The decision boundaries are orthogonal to the axes, since the splits are made based on individual features at each internal node.\n",
    "\n",
    "# Prediction is intuitive: when a new data point is introduced, it follows the decision boundaries from the root node down to a leaf node, and the majority class of the training samples in that leaf node becomes the predicted class for the new point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f9710b4-676d-431a-a5b2-ace29aa90ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5\n",
    "\n",
    "# A confusion matrix is a table that is often used to describe the performance of a classification model on a set of data for which the true values are known. It helps us understand how well the model is doing in terms of predicting different classes. In a binary classification problem, the confusion matrix consists of four values:\n",
    "\n",
    "# True Positive (TP): The number of instances correctly predicted as positive.\n",
    "# True Negative (TN): The number of instances correctly predicted as negative.\n",
    "# False Positive (FP): The number of instances predicted as positive but are actually negative (Type I error).\n",
    "# False Negative (FN): The number of instances predicted as negative but are actually positive (Type II error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aaf7220-f5d0-411b-af7b-dbc800506ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6\n",
    "\n",
    "# Let's consider a binary classification problem for predicting whether an email is spam (positive class) or not (negative class). Here's a hypothetical confusion matrix:\n",
    "#               Predicted\n",
    "#             |  Spam  |  Not Spam\n",
    "# Actual      |--------|----------\n",
    "# Spam        |   150  |    25\n",
    "# Not Spam    |    10  |   315\n",
    "\n",
    "# From this matrix, we can calculate:\n",
    "\n",
    "# Precision: Precision is the ratio of correctly predicted positive observations to the total predicted positives (TP / (TP + FP)).\n",
    "# Recall (Sensitivity or True Positive Rate): Recall is the ratio of correctly predicted positive observations to the total actual positives (TP / (TP + FN)).\n",
    "# F1 Score: The F1 Score is the weighted average of precision and recall, which ranges between 0 and 1. It is calculated as 2 * ((Precision * Recall) / (Precision + Recall)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1b42a4-d8b4-40b5-a047-e398586639cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7\n",
    "\n",
    "# Choosing the right evaluation metric is crucial because different metrics provide insights into different aspects of a model's performance. The choice depends on the problem's context and the trade-offs between false positives and false negatives.\n",
    "\n",
    "# For example:\n",
    "\n",
    "# If the cost of false positives is high (e.g., in medical diagnosis), you would focus on high precision.\n",
    "# If the cost of false negatives is high (e.g., detecting fraud), you would prioritize high recall.\n",
    "# To choose the appropriate metric, consider the business impact, user expectations, and the specific goals of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c91d38-c578-4d28-bdf3-04c9f2f4c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8\n",
    "\n",
    "# Consider a spam email classifier. In this case, precision is important because falsely classifying a legitimate email as spam (false positive) can have significant consequences, such as important messages being missed. Maximizing precision helps reduce the chances of false positives, ensuring that emails classified as spam are highly likely to be spam.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc32935-70ca-463e-b297-f7f2585a5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 9\n",
    "\n",
    "# Imagine a model for detecting rare diseases. Here, recall is crucial because missing a positive case (false negative) can lead to severe consequences, including delayed treatment or potential harm to the patient. Maximizing recall ensures that the model identifies as many positive cases as possible, even if it means having a higher number of false positives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
