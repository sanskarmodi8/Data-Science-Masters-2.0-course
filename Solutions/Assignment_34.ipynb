{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88335e8a-8528-4346-9e83-a5f8579e255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1\n",
    "\n",
    "# Independence: The data points within each group should be independent of each other.\n",
    "# Normality: The residuals (the differences between the observed values and the predicted values) of each group should be approximately normally distributed.\n",
    "# Homogeneity of Variance: The variance of the residuals should be equal across all groups.\n",
    "# Violations and Impact on Validity:\n",
    "\n",
    "# Independence: Violation of this assumption can lead to biased results and inaccurate estimates of the variances between groups.\n",
    "# Normality: If the normality assumption is violated, the p-values and confidence intervals may be incorrect, leading to erroneous conclusions about group differences.\n",
    "# Homogeneity of Variance: When violated, the F-statistic can become unreliable, resulting in incorrect identification of significant differences between groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7439c35f-a766-40f6-bc5d-e3bb21f61aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2\n",
    "\n",
    "# One-Way ANOVA: Used to compare means of three or more groups on a single independent variable (factor).\n",
    "# Two-Way ANOVA: Used to examine the main effects of two independent variables (factors) and their interaction on the dependent variable.\n",
    "# Repeated Measures ANOVA: Used when the same participants are measured multiple times under different conditions or at different time points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b076774-5a96-4401-ab50-7c929b62893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3\n",
    "\n",
    "# In ANOVA, the total variance in the data is partitioned into different components:\n",
    "\n",
    "# Total Sum of Squares (SST): It represents the total variability in the data.\n",
    "# Explained Sum of Squares (SSE): It represents the variability explained by the factors or independent variables in the model.\n",
    "# Residual Sum of Squares (SSR): It represents the unexplained variability or the variability that cannot be attributed to the factors in the model.\n",
    "# Understanding this concept is crucial because the F-statistic, which is used to test for significant differences, is calculated by comparing the explained variance to the unexplained variance. By understanding the partitioning of variance, researchers can assess the proportion of variance explained by the factors and determine the overall fit of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0725c38-2a9f-49eb-9617-10ebba95ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4\n",
    "\n",
    "# import numpy as np\n",
    "# from scipy.stats import f_oneway\n",
    "\n",
    "# # Assuming you have three groups A, B, and C, and their respective weight loss data\n",
    "# group_A = [2.5, 3.0, 2.2, ...]  # Replace ... with the actual data\n",
    "# group_B = [1.8, 2.2, 1.5, ...]\n",
    "# group_C = [2.0, 2.5, 2.3, ...]\n",
    "\n",
    "# # Combine all the data into a single array\n",
    "# data = np.concatenate([group_A, group_B, group_C])\n",
    "\n",
    "# # Create corresponding group labels\n",
    "# groups = ['A'] * len(group_A) + ['B'] * len(group_B) + ['C'] * len(group_C)\n",
    "\n",
    "# # Perform one-way ANOVA\n",
    "# f_statistic, p_value = f_oneway(group_A, group_B, group_C)\n",
    "\n",
    "# # Calculate degrees of freedom\n",
    "# df_total = len(data) - 1\n",
    "# df_groups = len(np.unique(groups)) - 1\n",
    "# df_error = df_total - df_groups\n",
    "\n",
    "# # Calculate sum of squares\n",
    "# mean_total = np.mean(data)\n",
    "# sst = np.sum((data - mean_total) ** 2)\n",
    "# sse = np.sum((group_A - np.mean(group_A)) ** 2) + np.sum((group_B - np.mean(group_B)) ** 2) + np.sum((group_C - np.mean(group_C)) ** 2)\n",
    "# ssr = sst - sse\n",
    "\n",
    "# print(\"Total Sum of Squares (SST):\", sst)\n",
    "# print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "# print(\"Residual Sum of Squares (SSR):\", ssr)\n",
    "# print(\"F-statistic:\", f_statistic)\n",
    "# print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b35f4df5-3fde-43c3-9ce2-7ac84aba11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5\n",
    "\n",
    "# import pandas as pd\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.formula.api import ols\n",
    "\n",
    "# # Assuming you have a DataFrame with columns 'Software', 'Experience', and 'TimeTaken'\n",
    "# # Software: A, B, or C\n",
    "# # Experience: Novice or Experienced\n",
    "# # TimeTaken: Time to complete the task\n",
    "\n",
    "# # Example DataFrame\n",
    "# data = pd.DataFrame({\n",
    "#     'Software': ['A', 'B', 'C', ...],  # Replace ... with the actual data\n",
    "#     'Experience': ['Novice', 'Experienced', 'Novice', ...],\n",
    "#     'TimeTaken': [20, 25, 18, ...]\n",
    "# })\n",
    "\n",
    "# # Convert Software and Experience columns to categorical variables\n",
    "# data['Software'] = pd.Categorical(data['Software'])\n",
    "# data['Experience'] = pd.Categorical(data['Experience'])\n",
    "\n",
    "# # Perform two-way ANOVA\n",
    "# model = ols('TimeTaken ~ Software + Experience + Software:Experience', data=data).fit()\n",
    "# anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# # Extract main effects and interaction effects\n",
    "# main_effects = anova_table.iloc[:-1, :-1]\n",
    "# interaction_effect = anova_table.iloc[-1, :-1]\n",
    "\n",
    "# print(\"Main Effects:\")\n",
    "# print(main_effects)\n",
    "# print(\"\\nInteraction Effect:\")\n",
    "# print(interaction_effect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7b818-1028-468b-957a-c193e27543ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6\n",
    "\n",
    "# In a one-way ANOVA, the F-statistic tests whether there are significant differences between the means of the groups. The p-value indicates the probability of obtaining such a result if there were no true differences between the group means.\n",
    "\n",
    "# In the given scenario:\n",
    "\n",
    "# F-statistic: 5.23\n",
    "# p-value: 0.02\n",
    "# Interpretation:\n",
    "# Since the p-value (0.02) is less than the significance level (usually set at 0.05), we can reject the null hypothesis, which states that there are no significant differences between the group means. Therefore, we have evidence to suggest that there are significant differences between at least two of the groups. However, the ANOVA itself does not tell us which specific groups are different from each other. To identify those differences, we need to conduct post-hoc tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd98e72-e98c-42d8-bc8b-825411a50057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7\n",
    "\n",
    "# Handling missing data in repeated measures ANOVA can be crucial for obtaining accurate and reliable results. The methods for handling missing data depend on the nature of the missingness and the assumptions made about the missing data mechanism. Some common approaches include:\n",
    "\n",
    "# Complete Case Analysis (Listwise deletion): This method involves excluding any participant who has missing data in any of the repeated measures. While it is straightforward, it can lead to a loss of statistical power, especially if the missing data are not missing completely at random (MCAR).\n",
    "\n",
    "# Mean Imputation: Replace missing values with the mean of the available data for that variable. This method can distort the variability and correlations between variables, leading to biased estimates.\n",
    "\n",
    "# Last Observation Carried Forward (LOCF): Carry forward the last observed value for each participant to replace the missing data. This method may not accurately reflect the true values over time and can introduce bias.\n",
    "\n",
    "# Multiple Imputation: This involves creating multiple plausible imputations for the missing data, considering the uncertainty of imputation. The analyses are then performed for each imputed dataset, and the results are combined to obtain the final inference. Multiple imputation is generally preferred when data are missing at random (MAR) and has the advantage of providing valid standard errors.\n",
    "\n",
    "# The potential consequences of using different methods to handle missing data include biased parameter estimates, inflated or deflated standard errors, incorrect p-values, and misleading conclusions about the effects of the variables. Therefore, it is essential to carefully consider the missing data mechanism and choose an appropriate method for handling missing data to minimize potential biases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5888128d-945d-4997-9306-9068a577dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8\n",
    "\n",
    "# Common post-hoc tests used after ANOVA include:\n",
    "\n",
    "# Tukey's Honestly Significant Difference (HSD) test: This test compares all possible pairs of group means and controls the familywise error rate. It is used when the sample sizes are equal, and it is highly versatile and widely used.\n",
    "\n",
    "# Bonferroni correction: This method adjusts the significance level for multiple comparisons, reducing the probability of making a Type I error. It is used when conducting multiple pairwise comparisons and can be more conservative than Tukey's test.\n",
    "\n",
    "# Scheffe's method: Scheffe's method is a conservative post-hoc test used for unequal sample sizes. It is robust but has lower power compared to other post-hoc tests.\n",
    "\n",
    "# Dunnett's test: This test is used when comparing multiple treatments against a control group. It controls the overall type I error rate when testing treatments against a control.\n",
    "\n",
    "# Example of when a post-hoc test might be necessary:\n",
    "\n",
    "# Suppose you conducted a one-way ANOVA to compare the effectiveness of four different drug treatments for reducing blood pressure. The ANOVA results indicate that there is a significant difference among the treatments. Now, you want to determine which specific drug treatments are significantly different from each other. In this case, a post-hoc test like Tukey's HSD or Bonferroni correction would be appropriate to identify the pairwise differences between the treatments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f44a469-6f6d-42d3-8708-9b963c619079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 14.0\n",
      "p-value: 0.0007289999999999998\n",
      "There are significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "# Answer 9\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for weight loss in each diet group\n",
    "diet_a = [3, 5, 4, 6, 2]\n",
    "diet_b = [1, 2, 3, 4, 5]\n",
    "diet_c = [6, 7, 8, 9, 10]\n",
    "\n",
    "# Combine the data into a single array\n",
    "data = np.concatenate([diet_a, diet_b, diet_c])\n",
    "\n",
    "# Labels for the three diet groups\n",
    "labels = ['Diet A'] * len(diet_a) + ['Diet B'] * len(diet_b) + ['Diet C'] * len(diet_c)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_a, diet_b, diet_c)\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There are significant differences between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"There are no significant differences between the mean weight loss of the three diets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27407c0e-f9f7-4add-b55c-9169a8cf22c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 5.4353558455536275\n",
      "p-value: 0.03155392141528926\n",
      "There is a significant difference in test scores between the two groups.\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      " group1    group2    meandiff p-adj  lower   upper  reject\n",
      "----------------------------------------------------------\n",
      "Control Experimental      6.7 0.0316 0.6623 12.7377   True\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Answer 10\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data for test scores in control and experimental groups\n",
    "control_group = [78, 80, 85, 70, 72, 90, 84, 88, 82, 75]\n",
    "experimental_group = [85, 87, 92, 76, 79, 95, 89, 93, 91, 84]\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "df = pd.DataFrame({'Control': control_group, 'Experimental': experimental_group})\n",
    "\n",
    "# Melt the DataFrame to long format for repeated measures ANOVA\n",
    "df_melted = pd.melt(df, var_name='Group', value_name='TestScore')\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "model = ols('TestScore ~ Group', data=df_melted).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract F-statistic and p-value\n",
    "f_statistic = anova_table['F'][0]\n",
    "p_value = anova_table['PR(>F)'][0]\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in test scores between the two groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the two groups.\")\n",
    "\n",
    "# If the results are significant, you can follow up with a post-hoc test\n",
    "if p_value < 0.05:\n",
    "    # For example, you can perform Tukey's HSD test\n",
    "    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "    tukey_result = pairwise_tukeyhsd(df_melted['TestScore'], df_melted['Group'], alpha=0.05)\n",
    "\n",
    "    print(tukey_result)\n",
    "\n",
    "\n",
    "# Interpretation:\n",
    "\n",
    "# If the p-values for both \"SoftwareProgram\" and \"ExperienceLevel\" are less than 0.05, it indicates that there are significant main effects of both factors on completion time.\n",
    "# If the p-value for the \"SoftwareProgram:ExperienceLevel\" interaction effect is less than 0.05, it suggests that there is a significant interaction effect between the software programs and employee experience level, meaning that the effect of one factor depends on the level of the other factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "370da035-c8ee-4bc8-a36d-cb1097e6cbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -2.3313849629680625\n",
      "p-value: 0.03155392141528972\n",
      "There is a significant difference in test scores between the two groups.\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      " group1    group2    meandiff p-adj  lower   upper  reject\n",
      "----------------------------------------------------------\n",
      "Control Experimental      6.7 0.0316 0.6623 12.7377   True\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Answer 11\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for test scores in control and experimental groups\n",
    "control_group = [78, 80, 85, 70, 72, 90, 84, 88, 82, 75]\n",
    "experimental_group = [85, 87, 92, 76, 79, 95, 89, 93, 91, 84]\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in test scores between the two groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the two groups.\")\n",
    "\n",
    "# If the results are significant, you can follow up with a post-hoc test\n",
    "if p_value < 0.05:\n",
    "    # For example, you can perform Tukey's HSD test\n",
    "    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "    all_scores = control_group + experimental_group\n",
    "    group_labels = ['Control'] * len(control_group) + ['Experimental'] * len(experimental_group)\n",
    "\n",
    "    tukey_result = pairwise_tukeyhsd(endog=all_scores, groups=group_labels, alpha=0.05)\n",
    "\n",
    "    print(tukey_result)\n",
    "\n",
    "    \n",
    "# The Tukey's HSD test will provide you with information about which groups (if any) differ significantly in test scores after the initial two-sample t-test indicates a significant difference between the control and experimental groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ace8e6f5-c189-4e5c-ac3d-7ab64d3259a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 88.089304160015\n",
      "p-value: 1.2251435991564249e-21\n",
      "There are significant differences in average daily sales between the three stores.\n"
     ]
    }
   ],
   "source": [
    "# Answer 12\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for daily sales in three stores\n",
    "store_a_sales = [150, 160, 140, 170, 180, 155, 165, 175, 185, 180,\n",
    "                 160, 155, 170, 180, 190, 175, 165, 180, 170, 160,\n",
    "                 175, 185, 170, 180, 190, 160, 170, 165, 175, 180]\n",
    "\n",
    "store_b_sales = [140, 130, 120, 135, 145, 125, 135, 140, 150, 140,\n",
    "                 130, 125, 135, 140, 155, 145, 135, 140, 130, 120,\n",
    "                 135, 140, 145, 130, 120, 140, 135, 140, 150, 130]\n",
    "\n",
    "store_c_sales = [160, 150, 145, 155, 165, 140, 150, 160, 170, 160,\n",
    "                 150, 145, 155, 165, 175, 160, 150, 155, 165, 140,\n",
    "                 150, 160, 165, 145, 155, 170, 150, 155, 160, 145]\n",
    "\n",
    "# Combine the data into a single array\n",
    "all_sales = np.concatenate([store_a_sales, store_b_sales, store_c_sales])\n",
    "\n",
    "# Group labels\n",
    "group_labels = ['Store A'] * len(store_a_sales) + ['Store B'] * len(store_b_sales) + ['Store C'] * len(store_c_sales)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(store_a_sales, store_b_sales, store_c_sales)\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There are significant differences in average daily sales between the three stores.\")\n",
    "else:\n",
    "    print(\"There are no significant differences in average daily sales between the three stores.\")\n",
    "\n",
    "    \n",
    "# If the one-way ANOVA results are significant, indicating significant differences in average daily sales between the stores, you can perform a post-hoc test (e.g., Tukey's HSD) to determine which specific store(s) differ significantly from each other. However, since this is a one-way ANOVA scenario, there is no need for repeated measures analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c66eb-c283-4bb9-8fe4-4e69551aec9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
